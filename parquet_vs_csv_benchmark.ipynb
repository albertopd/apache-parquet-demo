{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a110242c",
   "metadata": {},
   "source": [
    "# Apache Parquet vs CSV - Benchmarking and Visualization\n",
    "\n",
    "This notebook demonstrates the advantages of using Apache Parquet over traditional CSV files for tabular data storage and analytics. Using a real-world books dataset, we compare file sizes and query performance between CSV and Parquet formats (including compressed and partitioned variants). Visualizations and benchmarks illustrate how Parquet can significantly reduce storage requirements and speed up data processing, especially for columnar queries and filtered reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path setup\n",
    "csv_file = \"data/books.csv\"\n",
    "parquet_default = \"data/books_default.parquet\"\n",
    "parquet_compressed = \"data/books_compressed.parquet\"\n",
    "parquet_partitioned = \"data/books_partitioned\"\n",
    "\n",
    "# Load CSV\n",
    "print(\"Loading CSV...\")\n",
    "df = pd.read_csv(csv_file)\n",
    "print(f\"Rows: {len(df)}, Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5901063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Parquet formats\n",
    "print(\"Exporting books CSV dataset to Parquet files...\")\n",
    "\n",
    "df.to_parquet(parquet_default, engine=\"fastparquet\", index=False)\n",
    "print(f\"Parquet file created with default settings: {parquet_default}\")\n",
    "\n",
    "df.to_parquet(parquet_compressed, engine=\"fastparquet\", compression=\"zstd\", index=False)\n",
    "print(f\"Parquet file created with ZStandard compression: {parquet_compressed}\")\n",
    "\n",
    "df.to_parquet(parquet_partitioned, engine=\"fastparquet\", compression=\"zstd\", partition_cols=[\"language\"], index=False)\n",
    "print(f\"Parquet files created with ZStandard compression and partitioning by language: {parquet_partitioned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare File Sizes\n",
    "def file_size(path):\n",
    "    if os.path.isdir(path):\n",
    "        return sum(os.path.getsize(os.path.join(root, f))\n",
    "                   for root, _, files in os.walk(path) for f in files)\n",
    "    else:\n",
    "        return os.path.getsize(path)\n",
    "\n",
    "sizes = {\n",
    "    \"CSV\": file_size(csv_file),\n",
    "    \"Parquet (default)\": file_size(parquet_default),\n",
    "    \"Parquet (compressed)\": file_size(parquet_compressed),\n",
    "    \"Parquet (comp/partioned)\": file_size(parquet_partitioned),\n",
    "}\n",
    "\n",
    "sizes_mb = {k: v/1024/1024 for k, v in sizes.items()}\n",
    "\n",
    "print(\" File Size Comparison \".center(51, '='))\n",
    "csv_size = sizes_mb[\"CSV\"]\n",
    "\n",
    "for name, size in sizes_mb.items():\n",
    "    if name == \"CSV\":\n",
    "        print(f\"{name:<25} {size:.2f} MB\")\n",
    "    else:\n",
    "        reduction = (1 - size / csv_size) * 100\n",
    "        print(f\"{name:<25} {size:.2f} MB  ({reduction:.1f}% smaller)\")\n",
    "\n",
    "# Plot file size comparison\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(sizes_mb.keys(), sizes_mb.values(), color=[\"#f39c12\",\"#2980b9\",\"#8e44ad\",\"#27ae60\"])\n",
    "plt.ylabel(\"File Size (MB)\")\n",
    "plt.title(\"File Size Comparison - CSV vs Parquet\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a629cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarks\n",
    "def benchmark(description, func):\n",
    "    \"\"\"Runs a benchmark measuring execution time and memory usage.\"\"\"\n",
    "    start = time.time()\n",
    "    _ = func()\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(f\"{description:<45} \"\n",
    "          f\"Time: {elapsed:.3f}s\")\n",
    "    return elapsed\n",
    "\n",
    "def print_percentage_faster(csv_benchmark, parquet_benchmark):\n",
    "    reduction = (1 - parquet_benchmark / csv_benchmark) * 100\n",
    "    print(f\" Parquet is {reduction:.1f}% faster than CSV\".rjust(58, \"=\"))\n",
    "\n",
    "benchmarks = {}\n",
    "\n",
    "# Case 1: Load full dataset\n",
    "print(\" Load Full Dataset \".center(58, \"=\"))\n",
    "\n",
    "benchmarks[\"CSV - Full Load\"] = benchmark(\n",
    "    \"CSV\", \n",
    "    lambda: pd.read_csv(csv_file))\n",
    "\n",
    "benchmarks[\"Parquet - Full Load\"] = benchmark(\n",
    "    \"Parquet\", \n",
    "    lambda: pd.read_parquet(parquet_default, engine=\"fastparquet\"))\n",
    "\n",
    "print_percentage_faster(benchmarks[\"CSV - Full Load\"], benchmarks[\"Parquet - Full Load\"])\n",
    "\n",
    "# Case 2: Column pruning (title, author, rating)\n",
    "print(\"\\n\" + \" Load Subset of Columns (title, author, rating) \".center(58, \"=\"))\n",
    "\n",
    "benchmarks[\"CSV - Subset Columns\"] = benchmark(\n",
    "    \"CSV - Column Subset\", \n",
    "    lambda: pd.read_csv(csv_file, usecols=[\"title\", \"author\", \"rating\"]))\n",
    "\n",
    "benchmarks[\"Parquet - Column Pruning\"] = benchmark(\n",
    "    \"Parquet - Column Pruning\", \n",
    "    lambda: pd.read_parquet(parquet_default, columns=[\"title\", \"author\", \"rating\"], engine=\"fastparquet\"))\n",
    "\n",
    "print_percentage_faster(benchmarks[\"CSV - Subset Columns\"], benchmarks[\"Parquet - Column Pruning\"])\n",
    "\n",
    "# Case 3: Predicate pushdown (rating > 4.5)\n",
    "print(\"\\n\" + \" Load Rows Where: rating > 4.5 \".center(58, \"=\"))\n",
    "\n",
    "benchmarks[\"CSV - Filter Rows\"] = benchmark(\n",
    "    \"CSV - Filter Rows After Load\", \n",
    "    lambda: pd.read_csv(csv_file)[lambda d: d[\"rating\"] > 4.5])\n",
    "\n",
    "benchmarks[\"Parquet - Predicate Pushdown\"] = benchmark(\n",
    "    \"Parquet - Predicate Pushdown\", \n",
    "    lambda: pd.read_parquet(parquet_default, filters=[(\"rating\", \">\", 4.5)], engine=\"fastparquet\"))\n",
    "\n",
    "print_percentage_faster(benchmarks[\"CSV - Filter Rows\"], benchmarks[\"Parquet - Predicate Pushdown\"])\n",
    "\n",
    "# Case 4: Partition pruning (English books only)\n",
    "print(\"\\n\" + \" Load Rows Where: language == 'English' \".center(58, \"=\"))\n",
    "\n",
    "benchmarks[\"CSV - Filter by Language\"] = benchmark(\n",
    "    \"CSV - Filter Rows After Load\", \n",
    "    lambda: pd.read_csv(csv_file)[lambda d: d[\"language\"] == \"English\"])\n",
    "\n",
    "benchmarks[\"Parquet - Read Language Partition\"] = benchmark(\n",
    "    \"Parquet - Partition Pruning\", \n",
    "    lambda: pd.read_parquet(os.path.join(parquet_partitioned, \"language=English\"), engine=\"fastparquet\"))\n",
    "\n",
    "print_percentage_faster(benchmarks[\"CSV - Filter by Language\"], benchmarks[\"Parquet - Read Language Partition\"])\n",
    "\n",
    "# Plot Benchmark Results as overlapping bars (grouped by case)\n",
    "\n",
    "# Group benchmarks by case\n",
    "cases = [\n",
    "    (\"Full Load\", \"CSV - Full Load\", \"Parquet - Full Load\"),\n",
    "    (\"Column Pruning\", \"CSV - Subset Columns\", \"Parquet - Column Pruning\"),\n",
    "    (\"Predicate Pushdown\", \"CSV - Filter Rows\", \"Parquet - Predicate Pushdown\"),\n",
    "    (\"Partition Pruning\", \"CSV - Filter by Language\", \"Parquet - Read Language Partition\"),\n",
    "]\n",
    "\n",
    "csv_times = [benchmarks[case[1]] for case in cases]\n",
    "parquet_times = [benchmarks[case[2]] for case in cases]\n",
    "labels = [case[0] for case in cases]\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(x - (width / 2), csv_times, width, label='CSV', color=\"#f39c12\")\n",
    "plt.bar(x + (width / 2), parquet_times, width, label='Parquet', color=\"#27ae60\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "plt.title(\"Performance Comparison - CSV vs Parquet\")\n",
    "plt.xticks(x, labels)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
